Round-1 coding assignment for **Teamwork AI**.

> **Goal** â€“ CLI agent: Generateâ†’Searchâ†’Reflectâ†’Synthesize â†’ JSON answer â‰¤ 80 words with citations.  
> Technologies: LangChain Â· LangGraph Â· Bing Search Â· OpenAI GPT-3.5-Turbo.

_âœï¸ Detailed design, setup, and trade-offs will be filled in as we progress._

## Quick Start

### Local dev (Python â‰¥3.11)

python -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt
python -m agent.cli "Who won the 2022 FIFA World Cup?"


### One-command Docker run

    docker compose run --rm agent "Compare Kubernetes HPA and KEDA"

If OPENAI_API_KEY / GEMINI_API_KEY / BING_API_KEY are absent, the agent falls back to deterministic mock mode so the command always works offline.


### Architecture

User Q â†’ GenerateQueries â†’ WebSearchTool â†’ Reflect âŸ³ (â‰¤2) â†’ Synthesize â†’ JSON

- Implemented as a LangGraph 0.5 pipeline with four async nodes.
- Retry on HTTP 429, 1-second timeout wrapper, mock fallback ensures CI is deterministic.


### Tests

    pytest -q          # 6 cases: happy, no-result, 429, timeout, two-round, CLI


### ğŸ”Œ Streaming API

| Type | URL | Example |
|------|-----|---------|
| **SSE** | `GET /api/stream?question=â€¦` |<br>`curl -N "http://localhost:8001/api/stream?question=Who+invented+Docker?"` |
| **WebSocket** | `ws://â€¦/api/ws?question=â€¦` |<br>`npx wscat -c "ws://localhost:8001/api/ws?question=Explain+Kubernetes+HPA"` |

The stream emits multiple `token` events followed by a final `done` payload that
contains the full answer and citations.
